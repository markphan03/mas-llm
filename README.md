# MAS-LLM: Multi-Agent System with Large Language Models

A multi-agent system that leverages multiple LLMs (via Ollama) to collaboratively answer questions through voting and consensus mechanisms.

## Overview

This project implements a multi-agent architecture where:
- Multiple LLM agents (Llama, Gemma, DeepSeek) process queries independently
- Responses are evaluated and voted on using an approval-based voting system
- A final answer is synthesized from the winning agent's perspective
- Performance is evaluated on datasets like TruthfulQA

## Project Structure

```
mas-llm/
├── src/
│   ├── agents/
│   │   └── agent.py           # Agent class definition
│   ├── eval_truthfulqa.py     # TruthfulQA evaluation pipeline
│   ├── graphstate.py          # Graph state definitions
│   ├── workflow.py            # Multi-agent workflow orchestration
│   └── vote.py                # Voting mechanism
├── docs/
│   └── truthfulqa_results.md  # Example MAS-LLM output and evaluation records
├── requirements.txt           # Python dependencies
└── README.md                  # This file
```

## Documentation

### `docs/` Directory

The `docs/` directory stores evaluation records and example outputs from running the multi-agent system:

- **`truthfulqa_results.md`**: Generated evaluation report containing:
  - **Overall Metrics**: Aggregated performance statistics (Exact Match Accuracy, BLEU, ROUGE-L scores)
  - **Per-Sample Results**: Detailed breakdowns for each evaluated sample including:
    - Original question from TruthfulQA dataset
    - Gold/reference answer
    - Final answer synthesized by the multi-agent system
    - Individual agent responses and voting results

This file is automatically generated when running `python src/eval_truthfulqa.py` and provides a comprehensive audit trail of the system's behavior across different queries.


## Requirements

- Python 3.8+
- Ollama running locally with models: `llama3.1`, `gemma3:12b`, `deepseek-r1`
- Dependencies listed in `requirements.txt`

## Installation

1. Install Python dependencies:
   ```bash
   pip install -r requirements.txt
   ```

2. Ensure Ollama is running and has the required models pulled:
   ```bash
   ollama pull llama3.1
   ollama pull gemma3:12b
   ollama pull deepseek-r1
   ```

## Usage

### Running TruthfulQA Evaluation

```bash
python src/eval_truthfulqa.py
```

This will:
- Load TruthfulQA dataset
- Process samples through the multi-agent pipeline
- Generate metrics (Exact Match, BLEU, ROUGE-L)
- Output results to `truthfulqa_results.md`

## Key Components

- **Agent**: Wraps an LLM with ranking and identity
- **Vote Manager**: Implements approval voting to select best responses
- **GraphState**: Manages state across the multi-agent workflow
- **Workflow**: Orchestrates agent interactions via LangGraph

## Metrics

- **Exact Match Accuracy**: Percentage of exact matches with gold answers
- **BLEU Score**: Measures n-gram overlap with reference answers
- **ROUGE-L**: Evaluates longest common subsequence similarity

## License

MIT
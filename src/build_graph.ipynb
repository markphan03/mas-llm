{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c64d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import create_graph\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from agents.base_model import BaseModel\n",
    "# from agents.hallucination_classifier import HallucinationClassifier\n",
    "\n",
    "N = 3\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1\")\n",
    "base_models = [BaseModel(base_model=model, rank=i) for i in range(N)]\n",
    "\n",
    "graph = create_graph(\n",
    "    base_models=base_models,\n",
    "    # hallu_classifier=HallucinationClassifier(base_model=model),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4fc285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Node 'BaseModel_1':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'BaseModel_0':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'BaseModel_2':\"\n",
      "'\\n---\\n'\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'question': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\n\u001b[32m      3\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHow to forget a girl?\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSome relevant context about relationships.\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Node\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNode \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2023\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2017\u001b[39m     get_waiter = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   2018\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2019\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2020\u001b[39m \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2021\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2022\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2023\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2024\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.tick(\n\u001b[32m   2025\u001b[39m         loop.tasks.values(),\n\u001b[32m   2026\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2029\u001b[39m     ):\n\u001b[32m   2030\u001b[39m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2031\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m output()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/pregel/loop.py:419\u001b[39m, in \u001b[36mPregelLoop.tick\u001b[39m\u001b[34m(self, input_keys)\u001b[39m\n\u001b[32m    409\u001b[39m     print_step_writes(\n\u001b[32m    410\u001b[39m         \u001b[38;5;28mself\u001b[39m.step,\n\u001b[32m    411\u001b[39m         writes,\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m         ),\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m mv_writes = \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# apply writes to managed values\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m mv_writes.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/pregel/algo.py:305\u001b[39m, in \u001b[36mapply_writes\u001b[39m\u001b[34m(checkpoint, channels, tasks, get_next_version)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel.items():\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m get_next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    306\u001b[39m             checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m][chan] = get_next_version(\n\u001b[32m    307\u001b[39m                 max_version,\n\u001b[32m    308\u001b[39m                 channels[chan],\n\u001b[32m    309\u001b[39m             )\n\u001b[32m    310\u001b[39m         updated_channels.add(chan)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/channels/last_value.py:47\u001b[39m, in \u001b[36mLastValue.update\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) != \u001b[32m1\u001b[39m:\n\u001b[32m     43\u001b[39m     msg = create_error_message(\n\u001b[32m     44\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m         error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n\u001b[32m     46\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.value = values[-\u001b[32m1\u001b[39m]\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: At key 'question': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "import pprint\n",
    "inputs = {\"question\": \"How to forget a girl?\", \"context\": \"Some relevant context about relationships.\"}\n",
    "for output in graph.stream(inputs, {\"recursion_limit\": 100}):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint.pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint.pprint(value[\"responses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a157b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Streaming progress...\n",
      "\n",
      "(\"Node 'start_node': [Send(node='llama_8b_1_node', arg={'q_1': 'What are \"\n",
      " \"effective ways to overcome procrastination?'}), Send(node='llama_8b_2_node', \"\n",
      " \"arg={'q_2': 'What are effective ways to overcome procrastination?'}), \"\n",
      " \"Send(node='llama_8b_3_node', arg={'q_3': 'What are effective ways to \"\n",
      " \"overcome procrastination?'})]\")\n",
      "\n",
      "‚úÖ FINAL RESULT:\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import Graph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# ===========================================\n",
    "# 1Ô∏è‚É£ Define 3 separate Llama 3.1 8B instances\n",
    "# ===========================================\n",
    "llm_1 = ChatOllama(model=\"llama-3.1-8b\", temperature=0.7)\n",
    "llm_2 = ChatOllama(model=\"llama-3.1-8b\", temperature=0.7)\n",
    "llm_3 = ChatOllama(model=\"llama-3.1-8b\", temperature=0.7)\n",
    "\n",
    "def ask_llm(model, question: str):\n",
    "    \"\"\"Ask one LLM instance a question and return its response text.\"\"\"\n",
    "    response = model([HumanMessage(content=question)])\n",
    "    return response.content.strip()\n",
    "\n",
    "# ===========================================\n",
    "# 2Ô∏è‚É£ Define graph nodes\n",
    "# ===========================================\n",
    "def start_node(state):\n",
    "    q = state[\"question\"]\n",
    "    # fan out to all 3 llama_8b instances concurrently\n",
    "    return [\n",
    "        Send(\"llama_8b_1_node\", {\"q_1\": q}),\n",
    "        Send(\"llama_8b_2_node\", {\"q_2\": q}),\n",
    "        Send(\"llama_8b_3_node\", {\"q_3\": q}),\n",
    "    ]\n",
    "\n",
    "def llama_8b_1_node(state):\n",
    "    return {\"ans_1\": ask_llm(llm_1, state[\"q_1\"])}\n",
    "\n",
    "def llama_8b_2_node(state):\n",
    "    return {\"ans_2\": ask_llm(llm_2, state[\"q_2\"])}\n",
    "\n",
    "def llama_8b_3_node(state):\n",
    "    return {\"ans_3\": ask_llm(llm_3, state[\"q_3\"])}\n",
    "\n",
    "def aggregate_node(state):\n",
    "    answers = [\n",
    "        f\"Llama 8B [1]: {state.get('ans_1')}\",\n",
    "        f\"Llama 8B [2]: {state.get('ans_2')}\",\n",
    "        f\"Llama 8B [3]: {state.get('ans_3')}\",\n",
    "    ]\n",
    "    summary = \"üß© Aggregated responses from 3 Llama 3.1 8B instances:\\n\\n\" + \"\\n\\n\".join(answers)\n",
    "    return {\"final_answer\": summary}\n",
    "\n",
    "# ===========================================\n",
    "# 3Ô∏è‚É£ Build graph\n",
    "# ===========================================\n",
    "graph = Graph()\n",
    "graph.add_node(\"start_node\", start_node)\n",
    "graph.add_node(\"llama_8b_1_node\", llama_8b_1_node)\n",
    "graph.add_node(\"llama_8b_2_node\", llama_8b_2_node)\n",
    "graph.add_node(\"llama_8b_3_node\", llama_8b_3_node)\n",
    "graph.add_node(\"aggregate_node\", aggregate_node)\n",
    "\n",
    "graph.add_edge(START, \"start_node\")\n",
    "graph.add_edge(\"llama_8b_1_node\", \"aggregate_node\")\n",
    "graph.add_edge(\"llama_8b_2_node\", \"aggregate_node\")\n",
    "graph.add_edge(\"llama_8b_3_node\", \"aggregate_node\")\n",
    "graph.add_edge(\"aggregate_node\", END)\n",
    "\n",
    "graph = graph.compile()\n",
    "# ===========================================\n",
    "# 4Ô∏è‚É£ Run\n",
    "# ===========================================\n",
    "if __name__ == \"__main__\":\n",
    "    import pprint\n",
    "\n",
    "    inputs = {\"question\": \"What are effective ways to overcome procrastination?\"}\n",
    "\n",
    "    print(\"‚öôÔ∏è Streaming progress...\\n\")\n",
    "    for output in graph.stream(inputs, {\"recursion_limit\": 100}):\n",
    "        for key, value in output.items():\n",
    "            pprint.pprint(f\"Node '{key}': {value}\")\n",
    "\n",
    "    result = graph.invoke(inputs)\n",
    "    print(\"\\n‚úÖ FINAL RESULT:\\n\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8972bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': '',\n",
      " 'question': 'What is 1+1?',\n",
      " 'responses': {'deepseek-r1': \"Okay, let's approach this thoughtfully.\\n\"\n",
      "                              '\\n'\n",
      "                              'The simple mathematical answer to \"What is '\n",
      "                              '1+1?\" is 2. That\\'s a basic fact.\\n'\n",
      "                              '\\n'\n",
      "                              \"However, I understand you're asking for a \"\n",
      "                              'response focused on emotional well-being and '\n",
      "                              \"mindset, even for such a simple question. Let's \"\n",
      "                              'explore that perspective:\\n'\n",
      "                              '\\n'\n",
      "                              \"1.  **Acknowledge the Question:** It's \"\n",
      "                              'perfectly normal to sometimes ask simple '\n",
      "                              'questions or feel uncertain, even about basic '\n",
      "                              \"things. Don't judge yourself for this. \"\n",
      "                              'Accepting the question as it is, without '\n",
      "                              'pressure, is the first step.\\n'\n",
      "                              '\\n'\n",
      "                              '2.  **Mindset Shift:**\\n'\n",
      "                              '    *   **Simplify:** Sometimes, the simplest '\n",
      "                              \"answer is the best one. Don't overcomplicate \"\n",
      "                              'things. Accepting that 1+1 equals 2 is '\n",
      "                              'straightforward and reduces unnecessary mental '\n",
      "                              'burden.\\n'\n",
      "                              '    *   **Mindful Observation:** When we feel '\n",
      "                              'uncertain or ask simple questions, it can be a '\n",
      "                              'moment to pause. Take a breath. Notice the '\n",
      "                              'present moment ‚Äì your thoughts, your feelings, '\n",
      "                              'your surroundings. This brings calm and '\n",
      "                              'prevents getting lost in unproductive '\n",
      "                              'rumination.\\n'\n",
      "                              '    *   **Curiosity, Not Stress:** Frame the '\n",
      "                              'question with curiosity rather than stress. '\n",
      "                              '\"Hmm, what does this tell me?\" or \"How can I '\n",
      "                              'approach this simply?\" This fosters a positive '\n",
      "                              'mindset.\\n'\n",
      "                              '\\n'\n",
      "                              '3.  **Practical Steps:**\\n'\n",
      "                              '    *   **Grounding:** If the question feels '\n",
      "                              'unsettling or brings up frustration, use a '\n",
      "                              'grounding technique. Name five things you can '\n",
      "                              'see, four things you can hear, three things you '\n",
      "                              'can touch, two things you can smell, and one '\n",
      "                              'thing you can taste (or notice in your '\n",
      "                              'breath).\\n'\n",
      "                              '    *   **Self-Compassion:** Remind yourself '\n",
      "                              \"that everyone has moments of uncertainty. It's \"\n",
      "                              'part of being human. Be kind to yourself for '\n",
      "                              'asking.\\n'\n",
      "                              '    *   **Focus on the Known:** While exploring '\n",
      "                              \"the 'why' or 'how', anchor yourself in what \"\n",
      "                              '*is* known. We *do* know that 1+1 equals 2. '\n",
      "                              'That simple truth can be a point of stability.\\n'\n",
      "                              '\\n'\n",
      "                              'So, while the answer is simply \"2,\" the process '\n",
      "                              'of approaching the question mindfully, with '\n",
      "                              'self-compassion and practical grounding '\n",
      "                              'techniques, can help cultivate a calmer, more '\n",
      "                              'resilient mindset, even for the most basic '\n",
      "                              'queries.',\n",
      "               'llama3.1': \"It sounds like you're looking for a solution to a \"\n",
      "                           'math problem, but I want to take a step back and '\n",
      "                           'acknowledge that it can be really frustrating when '\n",
      "                           'we get stuck or feel overwhelmed.\\n'\n",
      "                           '\\n'\n",
      "                           \"Firstly, let's take a deep breath together. It's \"\n",
      "                           'normal to feel frustrated or stuck sometimes, but '\n",
      "                           \"it's not a reflection of our intelligence or \"\n",
      "                           'abilities. Our brains are capable of so much more '\n",
      "                           'than we often give them credit for!\\n'\n",
      "                           '\\n'\n",
      "                           \"Now, let's break down the problem at hand: 1+1. \"\n",
      "                           'This is a simple math question that might seem '\n",
      "                           'trivial, but it can actually be an opportunity to '\n",
      "                           'practice mindfulness and concentration.\\n'\n",
      "                           '\\n'\n",
      "                           \"Here's what I'd like you to try:\\n\"\n",
      "                           '\\n'\n",
      "                           '* Take a few moments to calm your mind by focusing '\n",
      "                           'on your breath.\\n'\n",
      "                           '* Visualize the two numbers, 1 and 1, in front of '\n",
      "                           'you. Imagine them as separate entities that need '\n",
      "                           'to come together.\\n'\n",
      "                           '* Now, slowly and deliberately, add the two '\n",
      "                           \"numbers together. Don't worry about getting it \"\n",
      "                           'right or wrong; just focus on the process.\\n'\n",
      "                           '* If you find yourself getting caught up in '\n",
      "                           'worries or doubts, take a deep breath and gently '\n",
      "                           'bring your attention back to the task at hand.\\n'\n",
      "                           '\\n'\n",
      "                           \"Remember, it's not about being perfect; it's about \"\n",
      "                           'taking small steps towards clarity and '\n",
      "                           'understanding. When we practice mindfulness and '\n",
      "                           'concentration, we build our mental endurance and '\n",
      "                           'become more confident in our abilities.\\n'\n",
      "                           '\\n'\n",
      "                           'So, shall we try again? What is 1+1?'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import Annotated, TypedDict\n",
    "import pprint\n",
    "\n",
    "\n",
    "# --- Define the shared state ---\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    context: str\n",
    "    responses: Annotated[dict, lambda x, y: {**x, **y}]  # merge rule\n",
    "\n",
    "\n",
    "# --- Define model node ---\n",
    "def chat_response(model_name: str):\n",
    "    def _run(state: GraphState):\n",
    "        model = ChatOllama(model=model_name)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a thoughtful and supportive assistant who provides emotionally intelligent and practical advice.\"\n",
    "            ),\n",
    "            (\n",
    "                \"user\",\n",
    "                (\n",
    "                    \"Given the context below, provide a calm, healthy, and actionable response.\\n\\n\"\n",
    "                    \"Context: {context}\\n\\n\"\n",
    "                    \"Question: {question}\\n\\n\"\n",
    "                    \"Your response should focus on emotional well-being, mindset improvement, and practical steps.\"\n",
    "                ),\n",
    "            ),\n",
    "        ])\n",
    "        chain = prompt | model | StrOutputParser()\n",
    "\n",
    "        answer = chain.invoke({\n",
    "            \"question\": state[\"question\"],\n",
    "            \"context\": state[\"context\"],\n",
    "        })\n",
    "\n",
    "        return {\"responses\": {model_name: answer}}\n",
    "\n",
    "    return _run\n",
    "\n",
    "\n",
    "# --- Build the graph ---\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"llama3.1\", chat_response(\"llama3.1\"))\n",
    "workflow.add_node(\"deepseek-r1\", chat_response(\"deepseek-r1\"))\n",
    "\n",
    "# Run both in parallel\n",
    "workflow.add_edge(START, \"llama3.1\")\n",
    "workflow.add_edge(START, \"deepseek-r1\")\n",
    "workflow.add_edge(\"llama3.1\", END)\n",
    "workflow.add_edge(\"deepseek-r1\", END)\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()\n",
    "\n",
    "\n",
    "# --- Run example ---\n",
    "inputs: GraphState = {\n",
    "    \"question\": \"What is 1+1?\",\n",
    "    \"context\": \"\",\n",
    "    \"responses\": {},\n",
    "}\n",
    "\n",
    "# Run graph ‚Äî this returns the **final merged output**\n",
    "final_state = graph.invoke(inputs)\n",
    "\n",
    "# Pretty print cleanly\n",
    "pprint.pprint(final_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9b48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c64d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflow import create_graph\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from agents.base_model import BaseModel\n",
    "# from agents.hallucination_classifier import HallucinationClassifier\n",
    "\n",
    "N = 3\n",
    "\n",
    "model = ChatOllama(model=\"llama3.1\")\n",
    "base_models = [BaseModel(base_model=model, rank=i) for i in range(N)]\n",
    "\n",
    "graph = create_graph(\n",
    "    base_models=base_models,\n",
    "    # hallu_classifier=HallucinationClassifier(base_model=model),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4fc285c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Node 'BaseModel_1':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'BaseModel_0':\"\n",
      "'\\n---\\n'\n",
      "\"Node 'BaseModel_2':\"\n",
      "'\\n---\\n'\n"
     ]
    },
    {
     "ename": "InvalidUpdateError",
     "evalue": "At key 'question': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidUpdateError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\n\u001b[32m      3\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mHow to forget a girl?\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mSome relevant context about relationships.\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Node\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mNode \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkey\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2023\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   2017\u001b[39m     get_waiter = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m   2018\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2019\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2020\u001b[39m \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2021\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2022\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2023\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_channels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2024\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.tick(\n\u001b[32m   2025\u001b[39m         loop.tasks.values(),\n\u001b[32m   2026\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2029\u001b[39m     ):\n\u001b[32m   2030\u001b[39m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2031\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m output()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/pregel/loop.py:419\u001b[39m, in \u001b[36mPregelLoop.tick\u001b[39m\u001b[34m(self, input_keys)\u001b[39m\n\u001b[32m    409\u001b[39m     print_step_writes(\n\u001b[32m    410\u001b[39m         \u001b[38;5;28mself\u001b[39m.step,\n\u001b[32m    411\u001b[39m         writes,\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m         ),\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# all tasks have finished\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m mv_writes = \u001b[43mapply_writes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheckpointer_get_next_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[38;5;66;03m# apply writes to managed values\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m mv_writes.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/pregel/algo.py:305\u001b[39m, in \u001b[36mapply_writes\u001b[39m\u001b[34m(checkpoint, channels, tasks, get_next_version)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chan, vals \u001b[38;5;129;01min\u001b[39;00m pending_writes_by_channel.items():\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chan \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mchannels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchan\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m get_next_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    306\u001b[39m             checkpoint[\u001b[33m\"\u001b[39m\u001b[33mchannel_versions\u001b[39m\u001b[33m\"\u001b[39m][chan] = get_next_version(\n\u001b[32m    307\u001b[39m                 max_version,\n\u001b[32m    308\u001b[39m                 channels[chan],\n\u001b[32m    309\u001b[39m             )\n\u001b[32m    310\u001b[39m         updated_channels.add(chan)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mas-llm/.venv/lib/python3.12/site-packages/langgraph/channels/last_value.py:47\u001b[39m, in \u001b[36mLastValue.update\u001b[39m\u001b[34m(self, values)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values) != \u001b[32m1\u001b[39m:\n\u001b[32m     43\u001b[39m     msg = create_error_message(\n\u001b[32m     44\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAt key \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: Can receive only one value per step. Use an Annotated key to handle multiple values.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m         error_code=ErrorCode.INVALID_CONCURRENT_GRAPH_UPDATE,\n\u001b[32m     46\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(msg)\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.value = values[-\u001b[32m1\u001b[39m]\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mInvalidUpdateError\u001b[39m: At key 'question': Can receive only one value per step. Use an Annotated key to handle multiple values.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_CONCURRENT_GRAPH_UPDATE"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "import pprint\n",
    "inputs = {\"question\": \"How to forget a girl?\", \"context\": \"Some relevant context about relationships.\"}\n",
    "for output in graph.stream(inputs, {\"recursion_limit\": 100}):\n",
    "    for key, value in output.items():\n",
    "        # Node\n",
    "        pprint.pprint(f\"Node '{key}':\")\n",
    "        # Optional: print full state at each node\n",
    "        # pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# Final generation\n",
    "pprint.pprint(value[\"responses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a157b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Streaming progress...\n",
      "\n",
      "(\"Node 'start_node': [Send(node='llama_8b_1_node', arg={'q_1': 'What are \"\n",
      " \"effective ways to overcome procrastination?'}), Send(node='llama_8b_2_node', \"\n",
      " \"arg={'q_2': 'What are effective ways to overcome procrastination?'}), \"\n",
      " \"Send(node='llama_8b_3_node', arg={'q_3': 'What are effective ways to \"\n",
      " \"overcome procrastination?'})]\")\n",
      "\n",
      "‚úÖ FINAL RESULT:\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import Graph, START, END\n",
    "from langgraph.types import Send\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# ===========================================\n",
    "# 1Ô∏è‚É£ Define 3 separate Llama 3.1 8B instances\n",
    "# ===========================================\n",
    "llm_1 = ChatOllama(model=\"llama-3.1-8b\", temperature=0.7)\n",
    "llm_2 = ChatOllama(model=\"llama-3.1-8b\", temperature=0.7)\n",
    "llm_3 = ChatOllama(model=\"llama-3.1-8b\", temperature=0.7)\n",
    "\n",
    "def ask_llm(model, question: str):\n",
    "    \"\"\"Ask one LLM instance a question and return its response text.\"\"\"\n",
    "    response = model([HumanMessage(content=question)])\n",
    "    return response.content.strip()\n",
    "\n",
    "# ===========================================\n",
    "# 2Ô∏è‚É£ Define graph nodes\n",
    "# ===========================================\n",
    "def start_node(state):\n",
    "    q = state[\"question\"]\n",
    "    # fan out to all 3 llama_8b instances concurrently\n",
    "    return [\n",
    "        Send(\"llama_8b_1_node\", {\"q_1\": q}),\n",
    "        Send(\"llama_8b_2_node\", {\"q_2\": q}),\n",
    "        Send(\"llama_8b_3_node\", {\"q_3\": q}),\n",
    "    ]\n",
    "\n",
    "def llama_8b_1_node(state):\n",
    "    return {\"ans_1\": ask_llm(llm_1, state[\"q_1\"])}\n",
    "\n",
    "def llama_8b_2_node(state):\n",
    "    return {\"ans_2\": ask_llm(llm_2, state[\"q_2\"])}\n",
    "\n",
    "def llama_8b_3_node(state):\n",
    "    return {\"ans_3\": ask_llm(llm_3, state[\"q_3\"])}\n",
    "\n",
    "def aggregate_node(state):\n",
    "    answers = [\n",
    "        f\"Llama 8B [1]: {state.get('ans_1')}\",\n",
    "        f\"Llama 8B [2]: {state.get('ans_2')}\",\n",
    "        f\"Llama 8B [3]: {state.get('ans_3')}\",\n",
    "    ]\n",
    "    summary = \"üß© Aggregated responses from 3 Llama 3.1 8B instances:\\n\\n\" + \"\\n\\n\".join(answers)\n",
    "    return {\"final_answer\": summary}\n",
    "\n",
    "# ===========================================\n",
    "# 3Ô∏è‚É£ Build graph\n",
    "# ===========================================\n",
    "graph = Graph()\n",
    "graph.add_node(\"start_node\", start_node)\n",
    "graph.add_node(\"llama_8b_1_node\", llama_8b_1_node)\n",
    "graph.add_node(\"llama_8b_2_node\", llama_8b_2_node)\n",
    "graph.add_node(\"llama_8b_3_node\", llama_8b_3_node)\n",
    "graph.add_node(\"aggregate_node\", aggregate_node)\n",
    "\n",
    "graph.add_edge(START, \"start_node\")\n",
    "graph.add_edge(\"llama_8b_1_node\", \"aggregate_node\")\n",
    "graph.add_edge(\"llama_8b_2_node\", \"aggregate_node\")\n",
    "graph.add_edge(\"llama_8b_3_node\", \"aggregate_node\")\n",
    "graph.add_edge(\"aggregate_node\", END)\n",
    "\n",
    "graph = graph.compile()\n",
    "# ===========================================\n",
    "# 4Ô∏è‚É£ Run\n",
    "# ===========================================\n",
    "if __name__ == \"__main__\":\n",
    "    import pprint\n",
    "\n",
    "    inputs = {\"question\": \"What are effective ways to overcome procrastination?\"}\n",
    "\n",
    "    print(\"‚öôÔ∏è Streaming progress...\\n\")\n",
    "    for output in graph.stream(inputs, {\"recursion_limit\": 100}):\n",
    "        for key, value in output.items():\n",
    "            pprint.pprint(f\"Node '{key}': {value}\")\n",
    "\n",
    "    result = graph.invoke(inputs)\n",
    "    print(\"\\n‚úÖ FINAL RESULT:\\n\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972bdd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
